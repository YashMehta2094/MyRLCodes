{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1P5jOKUeZgBym2mwr9WKhhXZCacLrgtlx","timestamp":1697458758875}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install gymnasium\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DY_gUlSTO27h","executionInfo":{"status":"ok","timestamp":1697219387150,"user_tz":-330,"elapsed":6767,"user":{"displayName":"Saggurthi Dinesh be21b032","userId":"13882204813436495148"}},"outputId":"fa0eecd2-e748-4aaf-d398-e7828bd5a533"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"]}]},{"cell_type":"code","source":["!pip install minigrid"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZI_SDH5d-UV","executionInfo":{"status":"ok","timestamp":1697219391752,"user_tz":-330,"elapsed":4609,"user":{"displayName":"Saggurthi Dinesh be21b032","userId":"13882204813436495148"}},"outputId":"d75f3a5d-943a-46de-f246-b200e1079ad3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: minigrid in /usr/local/lib/python3.10/dist-packages (2.3.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from minigrid) (1.23.5)\n","Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from minigrid) (0.29.1)\n","Requirement already satisfied: pygame>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from minigrid) (2.5.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->minigrid) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->minigrid) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->minigrid) (0.0.4)\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/openai/CLIP.git\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8d5VVbWip0U","executionInfo":{"status":"ok","timestamp":1697219400630,"user_tz":-330,"elapsed":8883,"user":{"displayName":"Saggurthi Dinesh be21b032","userId":"13882204813436495148"}},"outputId":"3110034c-ee03-47de-961e-9a12d8265e36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-w2xhxl7b\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-w2xhxl7b\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n","Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->clip==1.0) (17.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n"]}]},{"cell_type":"code","source":["import gym\n","import minigrid"],"metadata":{"id":"JySx7NAkO54S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from minigrid.wrappers import *"],"metadata":{"id":"ZSrj_adcemxU","executionInfo":{"status":"ok","timestamp":1697219400631,"user_tz":-330,"elapsed":15,"user":{"displayName":"Saggurthi Dinesh be21b032","userId":"13882204813436495148"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"07bae127-f629-445c-8f0b-ae73266297c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["env = gym.make(\"BabyAI-GoToRedBallGrey-v0\", render_mode=\"rgb_array\", max_episode_steps=100)\n"],"metadata":{"id":"qDYzFA8npW5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install torch torchvision transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1aKphRAmkd3Y","executionInfo":{"status":"ok","timestamp":1697219406465,"user_tz":-330,"elapsed":5841,"user":{"displayName":"Saggurthi Dinesh be21b032","userId":"13882204813436495148"}},"outputId":"36ff93ee-d5d6-40f5-a373-017efb1cf0cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["from clip import clip\n"],"metadata":{"id":"xvwNmK9-po2I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from collections import namedtuple\n","from PIL import Image\n","import random\n","\n","# Check if a GPU is available; if not, use the CPU\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Load the CLIP model and preprocessing function\n","model, transform = clip.load(\"ViT-B/16\", device)\n","\n","# Define the DQN neural network\n","class DQN(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(DQN, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_size, 128),  # Input size based on your specific setup\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, output_size)  # Output size corresponds to the action space\n","        )\n","\n","    def forward(self, x):\n","        x = x.view(x.size(0), -1)  # Flatten the tensor\n","        return self.model(x)\n","\n","# Define a named tuple for storing transitions in the replay buffer\n","Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n","\n","# Define a class for the replay buffer\n","class ReplayBuffer:\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","# Define a data transformation pipeline using torchvision\n","#transform = Compose([Resize((32, 32)), ToTensor()])\n","\n","# Define a function to preprocess observations\n","def preprocess_observation(observation):\n","    # Preprocess the image\n","    image = Image.fromarray(observation['image'])\n","    image_transformed = transform(image).unsqueeze(0)  # Flatten the image tensor\n","    # Encode the image using the CLIP model\n","    with torch.no_grad():\n","        image_features = (model.encode_image(image_transformed.to(device))).to(device)\n","    # Tokenize the mission\n","    mission = clip.tokenize([observation['mission']])\n","    with torch.no_grad():\n","        text_features = (model.encode_text(mission.to(device))).to(device)\n","    # Extract the direction as a tensor\n","    direction = torch.tensor([observation['direction']]).unsqueeze(0).to(torch.float32)\n","\n","    return  image_features.to(device), direction.to(device), text_features.to(device)\n","\n","# Define a function to select an action using epsilon-greedy policy\n","def select_action(state):\n","    if random.random() < epsilon:\n","        return env.action_space.sample()\n","    else:\n","        q_values = dqn(state)\n","        return q_values.argmax().item()\n","\n","# Define hyperparameters and initialize the DQN models and optimizer\n","input_size = 1025  # Adjust based on specific input\n","output_size = env.action_space.n  # Number of possible actions\n","dqn = DQN(input_size, output_size).to(device)\n","target_dqn = DQN(input_size, output_size).to(device)\n","target_dqn.load_state_dict(dqn.state_dict())  # Initialize target network with the same weights\n","\n","epsilon = 1.0  # Initial exploration rate\n","epsilon_decay = 0.9  # Decay rate for exploration\n","min_epsilon = 0.1  # Minimum exploration rate\n","gamma = 0.99  # Discount factor\n","lr = 0.001  # Learning rate\n","batch_size = 32\n","memory_size = 10000\n","target_update_interval = 10\n","\n","# Initialize the replay buffer, loss function, and optimizer\n","memory = ReplayBuffer(memory_size)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(dqn.parameters(), lr=lr)\n","\n","# Specify the number of episodes for training\n","num_episodes = 100\n"],"metadata":{"id":"T7gm6LFakjmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for episode in range(num_episodes):\n","    # Reset the environment for a new episode\n","    observation = env.reset()\n","    obs = observation[0] # Extract the first observation\n","    image_features, direction, text_features = preprocess_observation(obs)\n","\n","    # Concatenate image, direction, and mission to form the initial state\n","    state = torch.cat((image_features, direction, text_features), dim=1)\n","    total_reward = 0\n","    done = False\n","\n","    while not done:\n","        # Select an action using an epsilon-greedy policy\n","        action = select_action(state.to(device))\n","\n","        # Take the selected action and observe the next state, reward, and done flag\n","        next_observation, reward, done, info, _ = env.step(action)\n","        next_image, next_direction, next_mission = preprocess_observation(next_observation)\n","        next_state = torch.cat((next_image, next_direction, next_mission), dim=1)\n","\n","        # Store the transition in the replay buffer\n","        memory.push(state, action, next_state, reward, done)\n","\n","        # If there are enough samples in the replay buffer, perform a DQN update\n","        if len(memory.memory) >= batch_size:\n","            transitions = memory.sample(batch_size)\n","\n","            # Separate and convert transition elements to tensors\n","            state_batch = torch.stack([t.state.to(device) for t in transitions]).to(device)\n","            action_batch = torch.tensor([t.action for t in transitions]).to(device)\n","            next_state_batch = torch.stack([t.next_state[0] for t in transitions]).to(device)\n","            reward_batch = torch.tensor([t.reward for t in transitions]).to(device)\n","            done_batch = torch.tensor([t.done for t in transitions]).to(device)\n","            done_batch = done_batch.float().to(device)  # Convert boolean tensor to float tensor\n","            state_batch = state_batch.view(state_batch.size(0), -1).to(device)\n","\n","            # Calculate Q-values for current and next state-action pairs\n","            q_values_current_state_action_pairs = dqn(state_batch).gather(1, action_batch.view(-1, 1)).squeeze(1)\n","            q_values_next_state_max_actions = dqn(next_state_batch).max(1)[0]\n","\n","            # Calculate expected Q-values for the current state-action pairs\n","            expected_q_values_current_state_action_pairs = reward_batch + gamma * q_values_next_state_max_actions * (1 - done_batch)\n","\n","            # Compute the loss and update the DQN model\n","            loss = criterion(q_values_current_state_action_pairs, expected_q_values_current_state_action_pairs)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        state = next_state\n","        total_reward += reward\n","\n","    # Update the target DQN every N episodes\n","    if episode % target_update_interval == 0:\n","        target_dqn.load_state_dict(dqn.state_dict())\n","\n","    # Decay the exploration rate\n","    epsilon = max(epsilon * epsilon_decay, min_epsilon)\n","\n","    # Print the episode's total reward\n","    print(f\"Episode {episode}, Total Reward: {total_reward}\")\n","\n","# Save the trained DQN model\n","torch.save(dqn.state_dict(), \"dqn_model.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5eemaCwHl18","outputId":"90aecd24-337c-4295-c69a-9dcd89e82922"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 0, Total Reward: -18.265625\n","Episode 1, Total Reward: -13.709375\n","Episode 2, Total Reward: -3.3171875\n","Episode 3, Total Reward: -2.3468750000000003\n","Episode 4, Total Reward: -2.1921875\n","Sampling rejected: unreachable object at (1, 1)\n","Episode 5, Total Reward: 0.0859375\n","Episode 6, Total Reward: -0.2796875000000001\n","Episode 7, Total Reward: -2.3609375\n","Episode 8, Total Reward: -8.0703125\n","Episode 9, Total Reward: -3.3734375000000005\n","Episode 10, Total Reward: -11.20625\n","Episode 11, Total Reward: -1.0953125\n","Episode 12, Total Reward: -0.15312499999999996\n","Episode 13, Total Reward: -0.37812500000000004\n","Episode 14, Total Reward: -0.18125000000000013\n","Sampling rejected: unreachable object at (6, 5)\n","Episode 15, Total Reward: -11.825000000000001\n","Episode 16, Total Reward: -2.3609375\n","Episode 17, Total Reward: 0.7609375\n","Episode 18, Total Reward: -4.1468750000000005\n","Episode 19, Total Reward: -13.765625\n","Episode 20, Total Reward: -1.4609375\n","Episode 21, Total Reward: 0.9578125\n","Episode 22, Total Reward: -0.11093750000000013\n","Episode 23, Total Reward: -6.0734375\n","Episode 24, Total Reward: -8.3375\n","Episode 25, Total Reward: -4.3296875\n","Episode 26, Total Reward: -0.30781250000000004\n","Episode 27, Total Reward: -6.3265625000000005\n","Episode 28, Total Reward: -3.6968750000000004\n","Episode 29, Total Reward: 0.12812499999999993\n","Episode 30, Total Reward: -0.7718750000000001\n","Sampling rejected: unreachable object at (3, 6)\n","Episode 31, Total Reward: -10.165625\n","Episode 32, Total Reward: -4.259375\n","Episode 33, Total Reward: -6.1015625\n","Episode 34, Total Reward: -3.1484375\n","Episode 35, Total Reward: -7.114062500000001\n","Sampling rejected: unreachable object at (6, 3)\n","Episode 36, Total Reward: -0.51875\n","Episode 37, Total Reward: 0.296875\n","Episode 38, Total Reward: -2.3046875\n","Episode 39, Total Reward: -6.9875\n","Sampling rejected: unreachable object at (6, 1)\n","Episode 40, Total Reward: -8.2953125\n","Episode 41, Total Reward: -10.3625\n","Episode 42, Total Reward: -1.5734375000000003\n","Episode 43, Total Reward: -2.09375\n","Episode 44, Total Reward: 0.3671875\n","Sampling rejected: unreachable object at (2, 1)\n","Episode 45, Total Reward: -18.7296875\n","Sampling rejected: unreachable object at (1, 1)\n","Episode 46, Total Reward: 0.8734375\n","Episode 47, Total Reward: -10.728125\n","Episode 48, Total Reward: -9.575000000000001\n","Episode 49, Total Reward: 0.296875\n","Episode 50, Total Reward: -0.5609375000000001\n","Sampling rejected: unreachable object at (2, 6)\n","Episode 51, Total Reward: -23.8203125\n","Episode 52, Total Reward: -11.375\n","Episode 53, Total Reward: -4.68125\n","Episode 54, Total Reward: -13.4\n","Episode 55, Total Reward: -9.828125\n","Episode 56, Total Reward: -2.9796875000000003\n","Sampling rejected: unreachable object at (3, 3)\n","Episode 57, Total Reward: 0.94375\n","Sampling rejected: unreachable object at (5, 2)\n","Sampling rejected: unreachable object at (1, 6)\n","Episode 58, Total Reward: -11.4453125\n","Episode 59, Total Reward: -14.4125\n","Episode 60, Total Reward: -15.396875000000001\n","Episode 61, Total Reward: -6.425\n","Episode 62, Total Reward: -8.928125\n","Episode 63, Total Reward: -20.065625\n","Episode 64, Total Reward: -1.2218750000000003\n","Episode 65, Total Reward: 0.775\n","Episode 66, Total Reward: -17.6046875\n","Episode 67, Total Reward: -0.7296875\n","Episode 68, Total Reward: 0.55\n","Episode 69, Total Reward: -2.6140625\n","Episode 70, Total Reward: -25.971875\n","Episode 71, Total Reward: -3.33125\n","Episode 72, Total Reward: -1.5593750000000002\n","Episode 73, Total Reward: -3.5140625000000005\n","Episode 74, Total Reward: -0.22343749999999996\n","Episode 75, Total Reward: -15.650000000000002\n","Episode 76, Total Reward: -2.8671875\n","Sampling rejected: unreachable object at (6, 1)\n","Episode 77, Total Reward: 0.7609375\n","Episode 78, Total Reward: 0.12812499999999993\n","Episode 79, Total Reward: -51.678125\n","Episode 80, Total Reward: -0.46250000000000013\n","Episode 81, Total Reward: -4.5265625\n","Episode 82, Total Reward: -0.7296875\n","Episode 83, Total Reward: -1.0109375000000003\n","Episode 84, Total Reward: 0.39531249999999996\n","Episode 85, Total Reward: -2.375\n","Episode 86, Total Reward: -1.0390625\n","Episode 87, Total Reward: -10.7421875\n","Episode 88, Total Reward: -0.828125\n","Episode 89, Total Reward: -0.940625\n","Episode 90, Total Reward: -0.6031250000000001\n","Episode 91, Total Reward: -13.723437500000001\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9RDPWlY4HywU"},"execution_count":null,"outputs":[]}]}